{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b49bb2e-065e-4a53-9b13-c80ee076489c",
   "metadata": {},
   "source": [
    "# Transcript Collection #\n",
    "\n",
    "### Pipeline processed most recently: Mar 07, 2024 ###\n",
    "\n",
    "**_All data collected from TalkBank's AphasiaBank under permission. Data are not public._**\n",
    "\n",
    "Input transcripts are located in `'../../../Aphasia_transcript/'` and `'../../../Control_transcript/'`.\n",
    "\n",
    "Output data are located in `'../../data/'`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15edab4-52c0-4fda-a5b8-54eb636f3d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-07\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pylangacq as pla\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74245d78-b9df-40b8-9070-ef15acb621ed",
   "metadata": {},
   "source": [
    "## 1. Download transcript and audio files from AphasiaBank’s website. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f11bcf-0c35-4aa6-ae84-866fe604a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of aphasia interviews: 551\n",
      "Total number of control interviews: 347\n"
     ]
    }
   ],
   "source": [
    "def count_files_in_directory(directory_path, file_extension=\".cha\"):\n",
    "    return len([f for f in os.listdir(directory_path) \n",
    "                if os.path.isfile(os.path.join(directory_path, f)) and f.endswith(file_extension)])\n",
    "\n",
    "aphasia_count = count_files_in_directory('../../../Aphasia_transcript/')\n",
    "control_count = count_files_in_directory('../../../Control_transcript/')\n",
    "\n",
    "print(f\"Total number of aphasia interviews: {aphasia_count}\")\n",
    "print(f\"Total number of control interviews: {control_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab8e6c-db9a-46c5-bdec-adcbf74121a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Collect `raw_transcription` from CHAT transcript files. ##\n",
    "\n",
    "## 2-1. Create `aphasia/control_all.csv` file. ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32436de1-ea6f-4332-8166-1ebbee58bd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../../data/aphasia_all_2024-03-07.csv\n",
      "Saved to ../../data/control_all_2024-03-07.csv\n"
     ]
    }
   ],
   "source": [
    "def process_directory(directory_path, output_csv):\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.cha'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            previous_line = \"\"\n",
    "            file_id = os.path.basename(file_path)\n",
    "\n",
    "            for line in lines:\n",
    "                if line.startswith(\"\\t\"):\n",
    "                    previous_line += \" \" + line.strip()\n",
    "                else:\n",
    "                    if previous_line and (previous_line.startswith(\"*PAR\") or previous_line.startswith(\"*IN\")):\n",
    "                        speaker_id = previous_line.split(\":\")[0].strip()\n",
    "                        speaker_tag = file_id.split('.')[0] + \"_\" + speaker_id[1:]\n",
    "\n",
    "                        raw_transcript = previous_line.split(\"\\t\")[1].split(\"\\x15\")[0].strip()\n",
    "\n",
    "                        if speaker_id.startswith(\"INV\") and raw_transcript == \"www .\":\n",
    "                            data.append([file_id, speaker_tag, raw_transcript, \"\", \"\"])\n",
    "                        else:\n",
    "                            time_mark_parts = previous_line.split(\"\\x15\")\n",
    "                            if len(time_mark_parts) > 1:\n",
    "                                start_time = time_mark_parts[1].split(\"_\")[0].strip()\n",
    "                                end_time = time_mark_parts[1].split(\"_\")[1].strip()\n",
    "\n",
    "                                data.append([file_id, speaker_tag, raw_transcript, start_time, end_time])\n",
    "\n",
    "                    previous_line = line.strip()\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['filename', 'speaker_id', 'raw_transcript', 'start_time', 'end_time'])\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved to {output_csv}\")\n",
    "\n",
    "process_directory('../../../Aphasia_transcript', f'../../data/aphasia_all_{current_date}.csv')\n",
    "process_directory('../../../Control_transcript', f'../../data/control_all_{current_date}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28707a1-6779-443c-a854-e39f3c381221",
   "metadata": {},
   "source": [
    "## 2-2. Make edits to the `aphasia/control_all.csv` file. ##\n",
    "\n",
    "`Baycrest9336a.cha` removed for having multiple participants.\\\n",
    "Change wrong INV tags to PAR tags. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0102bb9d-8b44-42bb-8bf0-35574b649d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasia_df = pd.read_csv(f'../../data/aphasia_all_{current_date}.csv')\n",
    "control_df = pd.read_csv(f'../../data/control_all_{current_date}.csv')\n",
    "\n",
    "def filter_rows(df):\n",
    "    return df[\n",
    "        df['speaker_id'].str.contains('_INV', case=False, na=False) & \n",
    "        df['raw_transcript'].str.contains('\\+\"\\s*', na=False)\n",
    "    ]\n",
    "\n",
    "aphasia_filtered = filter_rows(aphasia_df)\n",
    "control_filtered = filter_rows(control_df)\n",
    "combined_df = pd.concat([aphasia_filtered, control_filtered], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(f'../../data/combined_filtered_{current_date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a55a730-7ffe-4181-9930-abab941d4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_INV = pd.read_csv('../../data/Old data/wrong_INV_2023-09-27.csv')\n",
    "aphasia_df = pd.read_csv(f'../../data/aphasia_all_{current_date}.csv')\n",
    "control_df = pd.read_csv(f'../../data/control_all_{current_date}.csv')\n",
    "\n",
    "for index, row in wrong_INV.iterrows():\n",
    "    \n",
    "    mask_aphasia = aphasia_df.eq(row).all(axis=1)\n",
    "    aphasia_df.loc[mask_aphasia, 'speaker_id'] = aphasia_df.loc[mask_aphasia, 'speaker_id'].str.replace(\"_INV\", \"_PAR\")\n",
    "\n",
    "    mask_control = control_df.eq(row).all(axis=1)\n",
    "    control_df.loc[mask_control, 'speaker_id'] = control_df.loc[mask_control, 'speaker_id'].str.replace(\"_INV\", \"_PAR\")\n",
    "\n",
    "aphasia_df = aphasia_df[aphasia_df['filename'] != 'Baycrest9336a.cha']    \n",
    "\n",
    "aphasia_df.to_csv(f'../../data/aphasia_all_{current_date}.csv', index=False)\n",
    "control_df.to_csv(f'../../data/control_all_{current_date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52561b-8036-4aa0-a9f8-748048170ff5",
   "metadata": {},
   "source": [
    "## 2-3. Extract paticipant speech and create `aphasia/control_concat.csv` file. ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d6c14a-851f-409f-aebc-ab23288e7550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../../data/aphasia_concat_2024-03-07.csv\n",
      "Saved to ../../data/control_concat_2024-03-07.csv\n"
     ]
    }
   ],
   "source": [
    "def concatenate_rows(input_csv, output_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # df = df[~((df['speaker_id'].str.contains('_PAR')) & (df['raw_transcript'] == 'www .'))]\n",
    "\n",
    "    concatenated_rows = []\n",
    "    is_par = False\n",
    "    start_time = None\n",
    "    current_filename = None\n",
    "    inv_present = False \n",
    "    transcript = \"\"\n",
    "    previous_end_time = None\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if current_filename != row['filename']:\n",
    "            if is_par:\n",
    "                concatenated_rows.append({\n",
    "                    'filename': current_filename,\n",
    "                    'speaker_id': 'concat_PAR',\n",
    "                    'raw_transcript': transcript,\n",
    "                    'start_time': start_time,\n",
    "                    'end_time': end_time\n",
    "                })\n",
    "\n",
    "            is_par = False\n",
    "            inv_present = False\n",
    "            current_filename = row['filename']\n",
    "            transcript = \"\"\n",
    "            previous_end_time = None\n",
    "\n",
    "        if \"_IN\" in row['speaker_id']:\n",
    "            inv_present = True\n",
    "            if is_par:  \n",
    "                concatenated_rows.append({\n",
    "                    'filename': current_filename,\n",
    "                    'speaker_id': 'concat_PAR',\n",
    "                    'raw_transcript': transcript,\n",
    "                    'start_time': start_time,\n",
    "                    'end_time': end_time\n",
    "                })\n",
    "                is_par = False\n",
    "            transcript = \"\"\n",
    "            previous_end_time = None\n",
    "        elif \"_PAR\" in row['speaker_id']:\n",
    "            if is_par:  \n",
    "\n",
    "                if (row['end_time'] - start_time) > 240000:\n",
    "                    potential_split_idx = -1\n",
    "                    for i in range(idx-1, 0, -1):\n",
    "                        if (df.iloc[i]['end_time'] - df.iloc[i-1]['start_time']) >= 1:\n",
    "                            potential_split_idx = i\n",
    "                            break\n",
    "\n",
    "                    if potential_split_idx != -1:\n",
    "                        split_transcripts = transcript.split(' ')\n",
    "                        first_transcript = ' '.join(split_transcripts[:potential_split_idx])\n",
    "                        second_transcript = ' '.join(split_transcripts[potential_split_idx:])\n",
    "                        \n",
    "                        concatenated_rows.append({\n",
    "                            'filename': current_filename,\n",
    "                            'speaker_id': 'concat_PAR',\n",
    "                            'raw_transcript': first_transcript,\n",
    "                            'start_time': start_time,\n",
    "                            'end_time': df.iloc[potential_split_idx]['end_time']\n",
    "                        })\n",
    "\n",
    "                        start_time = df.iloc[potential_split_idx+1]['start_time']\n",
    "                        transcript = second_transcript\n",
    "                    else:\n",
    "\n",
    "                        concatenated_rows.append({\n",
    "                            'filename': current_filename,\n",
    "                            'speaker_id': 'concat_PAR',\n",
    "                            'raw_transcript': transcript,\n",
    "                            'start_time': start_time,\n",
    "                            'end_time': previous_end_time\n",
    "                        })\n",
    "                        start_time = row['start_time']\n",
    "                        transcript = row['raw_transcript']\n",
    "\n",
    "                transcript += ' ' + row['raw_transcript']\n",
    "                end_time = row['end_time']\n",
    "            else:  \n",
    "                is_par = True\n",
    "                start_time = row['start_time']\n",
    "                end_time = row['end_time']\n",
    "                transcript = row['raw_transcript']\n",
    "            previous_end_time = row['end_time']\n",
    "\n",
    "    if is_par:\n",
    "        concatenated_rows.append({\n",
    "            'filename': current_filename,\n",
    "            'speaker_id': 'concat_PAR',\n",
    "            'raw_transcript': transcript,\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time\n",
    "        })\n",
    "\n",
    "    concatenated_df = pd.DataFrame(concatenated_rows)\n",
    "    concatenated_df = concatenated_df.drop(columns=['speaker_id'])\n",
    "    concatenated_df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    print(f\"Saved to {output_csv}\")\n",
    "\n",
    "concatenate_rows(f'../../data/aphasia_all_{current_date}.csv', f'../../data/aphasia_concat_{current_date}.csv')\n",
    "concatenate_rows(f'../../data/control_all_{current_date}.csv', f'../../data/control_concat_{current_date}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38debf51-32ab-4216-96d5-b6642d9c46ea",
   "metadata": {},
   "source": [
    "## 2-4. Give segment ID to snippets and create `duration` column. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf59605-b5f9-410e-bd40-9afc140510e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_segment_names(df, original_filename):\n",
    "    \n",
    "    df['file_base'] = df['filename'].str.split('.').str[0]\n",
    "    df['segment_name'] = df['file_base'] + \"_\" + df['start_time'].astype(str) + \"_\" + df['end_time'].astype(str) + '.wav'\n",
    "    # df['segment_name'] = df['filename'] + \"_\" + df['start_time'].astype(str) + \"_\" + df['end_time'].astype(str) + '.wav'\n",
    "    df.drop('file_base', axis=1, inplace=True)\n",
    "    df.to_csv(original_filename, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "aphasia_df = pd.read_csv(f\"../../data/aphasia_concat_{current_date}.csv\")\n",
    "control_df = pd.read_csv(f\"../../data/control_concat_{current_date}.csv\")\n",
    "\n",
    "aphasia_df = add_segment_names(aphasia_df, f\"../../data/aphasia_concat_{current_date}.csv\")\n",
    "control_df = add_segment_names(control_df, f\"../../data/control_concat_{current_date}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1713bb7-6e46-4bf8-9a86-94ec61df5dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>raw_transcript</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>segment_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>fridriksson09b.cha</td>\n",
       "      <td>&amp;=chuckles well ‡ sɪndə˞ɛʔɛt@u [: Cinderella] ...</td>\n",
       "      <td>730492</td>\n",
       "      <td>970447</td>\n",
       "      <td>fridriksson09b_730492_970447.wav</td>\n",
       "      <td>239955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>scale18d.cha</td>\n",
       "      <td>&amp;-um (..) Cinderella . [+ gram] one [: once] [...</td>\n",
       "      <td>1111586</td>\n",
       "      <td>1351478</td>\n",
       "      <td>scale18d_1111586_1351478.wav</td>\n",
       "      <td>239892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13232</th>\n",
       "      <td>fridriksson01a.cha</td>\n",
       "      <td>okay . [+ exc] &amp;+st &amp;-um &amp;=lips:smack &amp;-um sɪn...</td>\n",
       "      <td>853763</td>\n",
       "      <td>1093628</td>\n",
       "      <td>fridriksson01a_853763_1093628.wav</td>\n",
       "      <td>239865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>elman01b.cha</td>\n",
       "      <td>okay ‡ there's a: (.) &lt;I think&gt; [//] for is a ...</td>\n",
       "      <td>604018</td>\n",
       "      <td>843878</td>\n",
       "      <td>elman01b_604018_843878.wav</td>\n",
       "      <td>239860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>thompson11a.cha</td>\n",
       "      <td>&lt;and the [/] the&gt; [//] &amp;-um your [//] she [//]...</td>\n",
       "      <td>3423199</td>\n",
       "      <td>3663054</td>\n",
       "      <td>thompson11a_3423199_3663054.wav</td>\n",
       "      <td>239855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename                                     raw_transcript  \\\n",
       "526    fridriksson09b.cha  &=chuckles well ‡ sɪndə˞ɛʔɛt@u [: Cinderella] ...   \n",
       "58           scale18d.cha  &-um (..) Cinderella . [+ gram] one [: once] [...   \n",
       "13232  fridriksson01a.cha  okay . [+ exc] &+st &-um &=lips:smack &-um sɪn...   \n",
       "2414         elman01b.cha  okay ‡ there's a: (.) <I think> [//] for is a ...   \n",
       "20479     thompson11a.cha  <and the [/] the> [//] &-um your [//] she [//]...   \n",
       "\n",
       "       start_time  end_time                       segment_name  duration  \n",
       "526        730492    970447   fridriksson09b_730492_970447.wav    239955  \n",
       "58        1111586   1351478       scale18d_1111586_1351478.wav    239892  \n",
       "13232      853763   1093628  fridriksson01a_853763_1093628.wav    239865  \n",
       "2414       604018    843878         elman01b_604018_843878.wav    239860  \n",
       "20479     3423199   3663054    thompson11a_3423199_3663054.wav    239855  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aphasia_df = pd.read_csv(f'../../data/aphasia_concat_{current_date}.csv')\n",
    "control_df = pd.read_csv(f'../../data/control_concat_{current_date}.csv')\n",
    "\n",
    "aphasia_df['duration'] = aphasia_df['end_time'] - aphasia_df['start_time']\n",
    "control_df['duration'] = control_df['end_time'] - control_df['start_time']\n",
    "\n",
    "aphasia_df = aphasia_df.sort_values(by='duration', ascending=False)\n",
    "control_df = control_df.sort_values(by='duration', ascending=False)\n",
    "\n",
    "aphasia_df.to_csv(f'../../data/aphasia_concat_{current_date}.csv', index=False)\n",
    "control_df.to_csv(f'../../data/control_concat_{current_date}.csv', index=False)\n",
    "\n",
    "aphasia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d89e73-3063-404f-ac26-2b08fd8b2b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files from Aphasia_transcript: {'Baycrest9336a.cha', '.ipynb_checkpoints', '.DS_Store'}\n",
      "Missing files from Control_transcript: {'.ipynb_checkpoints', '.DS_Store'}\n",
      "Number of unique filenames in aphasia_df: 550\n",
      "Number of unique filenames in control_df: 347\n"
     ]
    }
   ],
   "source": [
    "aphasia_df = pd.read_csv(f'../../data/aphasia_concat_{current_date}.csv')\n",
    "control_df = pd.read_csv(f'../../data/control_concat_{current_date}.csv')\n",
    "\n",
    "unique_aphasia_filenames = set(aphasia_df['filename'])\n",
    "unique_control_filenames = set(control_df['filename'])\n",
    "\n",
    "def check_missing_files(directory, unique_filenames):\n",
    "    all_files_in_directory = set(os.listdir(directory))\n",
    "\n",
    "    missing_files = all_files_in_directory - unique_filenames\n",
    "    \n",
    "    return missing_files\n",
    "\n",
    "missing_aphasia_files = check_missing_files('../../../Aphasia_transcript/', unique_aphasia_filenames)\n",
    "missing_control_files = check_missing_files('../../../Control_transcript/', unique_control_filenames)\n",
    "\n",
    "print(f\"Missing files from Aphasia_transcript: {missing_aphasia_files}\")\n",
    "print(f\"Missing files from Control_transcript: {missing_control_files}\")\n",
    "\n",
    "print(f\"Number of unique filenames in aphasia_df: {len(unique_aphasia_filenames)}\")\n",
    "print(f\"Number of unique filenames in control_df: {len(unique_control_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c205f9-6b8c-40ca-8c26-71bab61cc8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
